"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[3951],{1254(e,n,s){s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"agents/stella-agent/index","title":"Overview","description":"The full-featured conversational AI agent with advanced capabilities for production deployments.","source":"@site/docs/agents/stella-agent/index.md","sourceDirName":"agents/stella-agent","slug":"/agents/stella-agent/","permalink":"/STELLA_backend/docs/agents/stella-agent/","draft":false,"unlisted":false,"editUrl":"https://github.com/c4dhi/STELLA_backend/tree/main/docs-site/docs/agents/stella-agent/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Overview"},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/STELLA_backend/docs/agents/overview"},"next":{"title":"Overview","permalink":"/STELLA_backend/docs/agents/stella-agent/expert-pool-overview"}}');var t=s(4848),r=s(8453);const l={sidebar_position:1,title:"Overview"},d="stella-agent",o={},a=[{value:"Overview",id:"overview",level:2},{value:"Features",id:"features",level:2},{value:"Speech-to-Text (STT)",id:"speech-to-text-stt",level:3},{value:"Language Model (LLM)",id:"language-model-llm",level:3},{value:"Text-to-Speech (TTS)",id:"text-to-speech-tts",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Environment Variables",id:"environment-variables",level:3},{value:"Plan Templates",id:"plan-templates",level:3},{value:"Pipeline Architecture",id:"pipeline-architecture",level:2},{value:"Data Channel Messages",id:"data-channel-messages",level:2},{value:"Transcript Updates",id:"transcript-updates",level:3},{value:"Agent Status",id:"agent-status",level:3},{value:"Todo List Updates",id:"todo-list-updates",level:3},{value:"Tool Integration",id:"tool-integration",level:2},{value:"Resource Requirements",id:"resource-requirements",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Agent Not Responding",id:"agent-not-responding",level:3},{value:"Poor Audio Quality",id:"poor-audio-quality",level:3},{value:"High Latency",id:"high-latency",level:3},{value:"See Also",id:"see-also",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"stella-agent",children:"stella-agent"})}),"\n",(0,t.jsx)(n.p,{children:"The full-featured conversational AI agent with advanced capabilities for production deployments."}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"stella-agent"})," provides a complete voice AI pipeline with:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"High-quality speech recognition (STT)"}),"\n",(0,t.jsx)(n.li,{children:"Advanced language model integration (LLM)"}),"\n",(0,t.jsx)(n.li,{children:"Natural text-to-speech synthesis (TTS)"}),"\n",(0,t.jsx)(n.li,{children:"Real-time audio streaming via LiveKit"}),"\n",(0,t.jsx)(n.li,{children:"Tool/function calling support"}),"\n",(0,t.jsx)(n.li,{children:"Progress tracking and todo management"}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"/docs/agents/stella-agent/expert-pool-overview",children:"Expert Pool System"})})," for safe handling of sensitive topics"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,t.jsx)(n.h3,{id:"speech-to-text-stt",children:"Speech-to-Text (STT)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Provider"}),": Configurable (Sherpa, Whisper, etc.)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time transcription"}),": Continuous streaming recognition"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Interim results"}),": Show partial transcriptions as user speaks"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Multi-language"}),": Support for multiple languages"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"language-model-llm",children:"Language Model (LLM)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Provider"}),": OpenAI GPT models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Streaming responses"}),": Token-by-token generation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"System prompts"}),": Customizable agent personality"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Context management"}),": Conversation history tracking"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tool/function calling"}),": Execute custom tools during conversation"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"text-to-speech-tts",children:"Text-to-Speech (TTS)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Provider"}),": Configurable (Kokoro, ElevenLabs, etc.)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Voice selection"}),": Multiple voice options"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Streaming audio"}),": Low-latency audio generation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Interruption handling"}),": Stop speaking when user talks"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsx)(n.h3,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Variable"}),(0,t.jsx)(n.th,{children:"Description"}),(0,t.jsx)(n.th,{children:"Default"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"OPENAI_API_KEY"})}),(0,t.jsx)(n.td,{children:"OpenAI API key"}),(0,t.jsx)(n.td,{children:"Required"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"OPENAI_MODEL"})}),(0,t.jsx)(n.td,{children:"Model to use"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"gpt-4o"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"STT_PROVIDER"})}),(0,t.jsx)(n.td,{children:"Speech-to-text provider"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"sherpa"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"TTS_PROVIDER"})}),(0,t.jsx)(n.td,{children:"Text-to-speech provider"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kokoro"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"TTS_VOICE"})}),(0,t.jsx)(n.td,{children:"Voice for TTS"}),(0,t.jsx)(n.td,{children:"Provider default"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"SYSTEM_PROMPT"})}),(0,t.jsx)(n.td,{children:"Agent's system prompt"}),(0,t.jsx)(n.td,{children:"Default prompt"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ELEVENLABS_API_KEY"})}),(0,t.jsx)(n.td,{children:"ElevenLabs API key"}),(0,t.jsx)(n.td,{children:"Optional"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"plan-templates",children:"Plan Templates"}),"\n",(0,t.jsx)(n.p,{children:"Plans define the conversation structure and agent behavior:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "name": "Customer Support",\n  "systemPrompt": "You are a helpful customer support agent...",\n  "tools": ["search_knowledge_base", "create_ticket"],\n  "settings": {\n    "maxTurns": 20,\n    "timeout": 300\n  }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"pipeline-architecture",children:"Pipeline Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Audio In (LiveKit)\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 VAD (Voice   \u2502    Detects when user starts/stops speaking\n\u2502 Activity     \u2502\n\u2502 Detection)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STT Service  \u2502    Converts speech to text (streaming)\n\u2502 (Sherpa/     \u2502\n\u2502  Whisper)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 LLM Service  \u2502    Generates response (streaming)\n\u2502 (OpenAI)     \u2502    May call tools during generation\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 TTS Service  \u2502    Converts text to speech (streaming)\n\u2502 (Kokoro/     \u2502\n\u2502  ElevenLabs) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\nAudio Out (LiveKit)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"data-channel-messages",children:"Data Channel Messages"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"stella-agent"})," sends various messages through LiveKit's data channel:"]}),"\n",(0,t.jsx)(n.h3,{id:"transcript-updates",children:"Transcript Updates"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"{\n  type: 'transcript_chunk',\n  data: {\n    text: string,\n    is_final: boolean,\n    confidence: number,\n    timestamp: string,\n    participant_id: string\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"agent-status",children:"Agent Status"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"{\n  type: 'agent_status',\n  data: {\n    status: 'listening' | 'thinking' | 'speaking',\n    message?: string\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"todo-list-updates",children:"Todo List Updates"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"{\n  type: 'todo_list',\n  data: {\n    items: Array<{\n      id: string,\n      description: string,\n      status: 'pending' | 'in_progress' | 'completed'\n    }>\n  }\n}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"tool-integration",children:"Tool Integration"}),"\n",(0,t.jsx)(n.p,{children:"Agents can call custom tools during conversations:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from stella_sdk import Tool\n\nclass SearchKnowledgeBase(Tool):\n    name = "search_knowledge_base"\n    description = "Search the knowledge base for relevant information"\n\n    async def execute(self, query: str) -> str:\n        # Search logic here\n        return results\n'})}),"\n",(0,t.jsx)(n.h2,{id:"resource-requirements",children:"Resource Requirements"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Resource"}),(0,t.jsx)(n.th,{children:"Request"}),(0,t.jsx)(n.th,{children:"Limit"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"CPU"}),(0,t.jsx)(n.td,{children:"250m"}),(0,t.jsx)(n.td,{children:"1000m"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Memory"}),(0,t.jsx)(n.td,{children:"512Mi"}),(0,t.jsx)(n.td,{children:"2Gi"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"System Prompts"}),": Write clear, specific system prompts that define the agent's personality and constraints"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Error Handling"}),": Implement retry logic for external API calls (OpenAI, TTS providers)"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Monitoring"}),": Use the logging and metrics exposed by the agent for debugging"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Resource Limits"}),": Monitor memory usage, especially with long conversations"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Graceful Shutdown"}),": Handle SIGTERM signals properly to clean up connections"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(n.h3,{id:"agent-not-responding",children:"Agent Not Responding"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Check STT service is receiving audio:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'kubectl logs <agent-pod> -n ai-agents | grep "audio"\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Verify OpenAI API key is valid:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'kubectl logs <agent-pod> -n ai-agents | grep "openai"\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"poor-audio-quality",children:"Poor Audio Quality"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Check TTS service logs for errors"}),"\n",(0,t.jsx)(n.li,{children:"Verify network latency to TTS provider"}),"\n",(0,t.jsx)(n.li,{children:"Consider using a local TTS service for lower latency"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"high-latency",children:"High Latency"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Use streaming responses for faster first-token time"}),"\n",(0,t.jsxs)(n.li,{children:["Consider ",(0,t.jsx)(n.code,{children:"stella-light-agent"})," for simpler use cases"]}),"\n",(0,t.jsx)(n.li,{children:"Check resource allocation - may need more CPU"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/docs/agents/stella-agent/expert-pool-overview",children:"Expert Pool System"})," - Safe handling of sensitive queries"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/agent-sdk/overview",children:"Agent SDK Overview"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/agent-sdk/building-custom-agent",children:"Building Custom Agents"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/agent-sdk/audio-pipeline",children:"Audio Pipeline"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453(e,n,s){s.d(n,{R:()=>l,x:()=>d});var i=s(6540);const t={},r=i.createContext(t);function l(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);