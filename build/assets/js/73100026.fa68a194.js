"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[1122],{2076(e,n,t){t.d(n,{gj:()=>l,pn:()=>r});t(6540);var s=t(7714),o=t(4848);function r({number:e,title:n,children:t,code:r,language:l="bash",isLast:i=!1}){return(0,o.jsxs)("div",{className:"step",children:[(0,o.jsxs)("div",{className:"step__indicator",children:[(0,o.jsx)("div",{className:"step__number",children:e}),!i&&(0,o.jsx)("div",{className:"step__connector"})]}),(0,o.jsxs)("div",{className:"step__body",children:[(0,o.jsx)("h3",{className:"step__title",children:n}),(0,o.jsx)("div",{className:"step__content",children:t}),r&&(0,o.jsx)("div",{className:"step__code",children:(0,o.jsx)(s.A,{language:l,children:r})})]})]})}function l({children:e}){return(0,o.jsx)("div",{className:"steps",children:e})}},5393(e,n,t){t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"guides/custom-tools","title":"Custom Tools","description":"Add custom tools to extend agent capabilities","source":"@site/docs/guides/custom-tools.md","sourceDirName":"guides","slug":"/guides/custom-tools","permalink":"/STELLA_backend/docs/guides/custom-tools","draft":false,"unlisted":false,"editUrl":"https://github.com/c4dhi/STELLA_backend/tree/main/docs-site/docs/guides/custom-tools.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Custom Tools","description":"Add custom tools to extend agent capabilities"},"sidebar":"docsSidebar","previous":{"title":"Build Your Own Agent","permalink":"/STELLA_backend/docs/guides/build-your-own-agent"},"next":{"title":"Custom Agent Visualizers","permalink":"/STELLA_backend/docs/guides/add-custom-ui"}}');var o=t(4848),r=t(8453),l=t(2076);const i={sidebar_position:5,title:"Custom Tools",description:"Add custom tools to extend agent capabilities"},a="Custom Tools",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Architecture",id:"architecture",level:2},{value:"Creating a Custom Tool",id:"creating-a-custom-tool",level:2},{value:"Passing Tools to the LLM",id:"passing-tools-to-the-llm",level:2},{value:"How Tool Calling Works",id:"how-tool-calling-works",level:3},{value:"Getting Tool Schemas",id:"getting-tool-schemas",level:3},{value:"Complete LLM Integration Example",id:"complete-llm-integration-example",level:3},{value:"Using LLMService (Recommended)",id:"using-llmservice-recommended",level:3},{value:"Tool Choice Options",id:"tool-choice-options",level:3},{value:"Parallel Tool Execution",id:"parallel-tool-execution",level:3},{value:"Tool Components",id:"tool-components",level:2},{value:"BaseTool Properties",id:"basetool-properties",level:3},{value:"ToolResult",id:"toolresult",level:3},{value:"Parameters Schema",id:"parameters-schema",level:3},{value:"Example: Database Tool",id:"example-database-tool",level:2},{value:"Example: External API Tool",id:"example-external-api-tool",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Error Handling",id:"error-handling",level:3},{value:"Timeouts",id:"timeouts",level:3},{value:"Descriptive Names and Descriptions",id:"descriptive-names-and-descriptions",level:3},{value:"Dependency Injection",id:"dependency-injection",level:3},{value:"Testing Tools",id:"testing-tools",level:2},{value:"Built-in Tools",id:"built-in-tools",level:2},{value:"Next Steps",id:"next-steps",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"custom-tools",children:"Custom Tools"})}),"\n",(0,o.jsx)(n.p,{children:"Tools extend agent capabilities by allowing them to perform actions beyond conversation - calling APIs, querying databases, sending notifications, and more. This guide explains how to create and register custom tools using the STELLA SDK."}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"Tools in STELLA are:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Class-based"})," - Extend ",(0,o.jsx)(n.code,{children:"BaseTool"})," with typed parameters"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Async"})," - All tool execution is asynchronous"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Provider-agnostic"})," - Automatically convert to OpenAI or Anthropic schemas"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Composable"})," - Register any combination of tools per agent"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"agents/your-agent/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 your_agent/\n\u2502       \u251c\u2500\u2500 agent.py           # Main agent class\n\u2502       \u2514\u2500\u2500 tools/             # Custom tools directory\n\u2502           \u251c\u2500\u2500 __init__.py    # Tool exports\n\u2502           \u251c\u2500\u2500 weather.py     # Example tool\n\u2502           \u2514\u2500\u2500 database.py    # Another tool\n"})}),"\n",(0,o.jsx)(n.p,{children:"The SDK provides the tool infrastructure:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"stella_agent_sdk/tools/\n\u251c\u2500\u2500 base.py      # BaseTool, ToolResult, ToolCall\n\u251c\u2500\u2500 registry.py  # ToolRegistry for managing tools\n\u2514\u2500\u2500 executor.py  # ToolExecutor for LLM tool loop\n"})}),"\n",(0,o.jsx)(n.h2,{id:"creating-a-custom-tool",children:"Creating a Custom Tool"}),"\n",(0,o.jsxs)(l.gj,{children:[(0,o.jsxs)(l.pn,{number:1,title:"Create the tool class",children:[(0,o.jsxs)(n.p,{children:["Create a new file in your agent's ",(0,o.jsx)(n.code,{children:"tools/"})," directory:"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="tools/weather.py"',children:'from typing import Any, Dict\n\nfrom stella_agent_sdk.tools import BaseTool, ToolResult\n\n\nclass GetWeatherTool(BaseTool):\n    """Fetch current weather for a location."""\n\n    @property\n    def name(self) -> str:\n        return "get_weather"\n\n    @property\n    def description(self) -> str:\n        return (\n            "Get the current weather for a city. "\n            "Returns temperature, conditions, and humidity."\n        )\n\n    @property\n    def parameters_schema(self) -> Dict[str, Any]:\n        return {\n            "type": "object",\n            "properties": {\n                "city": {\n                    "type": "string",\n                    "description": "City name (e.g., \'San Francisco\')"\n                },\n                "units": {\n                    "type": "string",\n                    "enum": ["celsius", "fahrenheit"],\n                    "description": "Temperature units (default: celsius)"\n                }\n            },\n            "required": ["city"]\n        }\n\n    async def execute(\n        self,\n        city: str,\n        units: str = "celsius"\n    ) -> ToolResult:\n        """Execute the weather lookup."""\n        try:\n            # Call your weather API\n            response = await self._fetch_weather(city, units)\n\n            return ToolResult(\n                success=True,\n                data={\n                    "city": city,\n                    "temperature": response["temp"],\n                    "units": units,\n                    "conditions": response["conditions"],\n                    "humidity": response["humidity"]\n                }\n            )\n        except Exception as e:\n            return ToolResult(\n                success=False,\n                error=f"Failed to fetch weather: {str(e)}"\n            )\n\n    async def _fetch_weather(\n        self,\n        city: str,\n        units: str\n    ) -> dict:\n        """Internal method to call weather API."""\n        import httpx\n\n        async with httpx.AsyncClient() as client:\n            resp = await client.get(\n                "https://api.weather.example/current",\n                params={"city": city, "units": units}\n            )\n            resp.raise_for_status()\n            return resp.json()\n'})})]}),(0,o.jsxs)(l.pn,{number:2,title:"Export from tools module",children:[(0,o.jsxs)(n.p,{children:["Create or update ",(0,o.jsx)(n.code,{children:"tools/__init__.py"}),":"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="tools/__init__.py"',children:'from .weather import GetWeatherTool\nfrom .database import QueryDatabaseTool, InsertRecordTool\n\n# List of all tools for easy registration\nALL_TOOLS = [\n    GetWeatherTool,\n    QueryDatabaseTool,\n    InsertRecordTool,\n]\n\n__all__ = [\n    "GetWeatherTool",\n    "QueryDatabaseTool",\n    "InsertRecordTool",\n    "ALL_TOOLS",\n]\n'})})]}),(0,o.jsxs)(l.pn,{number:3,title:"Register tools in your agent",children:[(0,o.jsx)(n.p,{children:"In your agent's initialization, register the tools:"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="agent.py"',children:'from stella_agent_sdk.tools import ToolRegistry\nfrom .tools import GetWeatherTool, QueryDatabaseTool\n\n\nclass MyAgent:\n    def __init__(self):\n        # Create tool registry\n        self.tool_registry = ToolRegistry()\n\n        # Register individual tools\n        self.tool_registry.register(GetWeatherTool())\n        self.tool_registry.register(QueryDatabaseTool(self.db_client))\n\n    def get_tools_for_llm(self):\n        """Get tool schemas for LLM call."""\n        return self.tool_registry.get_openai_schemas()\n'})}),(0,o.jsx)(n.p,{children:"Or register multiple tools at once:"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from .tools import ALL_TOOLS\n\nclass MyAgent:\n    def __init__(self):\n        self.tool_registry = ToolRegistry()\n\n        # Register all tools\n        for tool_class in ALL_TOOLS:\n            self.tool_registry.register(tool_class())\n"})})]}),(0,o.jsxs)(l.pn,{number:4,title:"Execute tools from LLM responses",isLast:!0,children:[(0,o.jsxs)(n.p,{children:["Use the ",(0,o.jsx)(n.code,{children:"ToolExecutor"})," to handle the tool calling loop:"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="agent.py"',children:'from stella_agent_sdk.tools import ToolExecutor, ToolCall\n\n\nclass MyAgent:\n    def __init__(self):\n        self.tool_registry = ToolRegistry()\n        self.tool_executor = ToolExecutor(self.tool_registry)\n        # ... register tools\n\n    async def process_llm_response(self, response):\n        """Process LLM response and execute any tool calls."""\n\n        # Parse tool calls from response\n        tool_calls = self.tool_executor.parse_openai_tool_calls(response)\n\n        if not tool_calls:\n            # No tools called, return text response\n            return response.choices[0].message.content\n\n        # Execute each tool\n        tool_results = []\n        async for event in self.tool_executor.execute_tool_calls(tool_calls):\n            if event.type.value == "tool_result":\n                tool_results.append(\n                    self.tool_executor.build_tool_result_message_openai(\n                        event.tool_call_id,\n                        event.result\n                    )\n                )\n\n        return tool_results\n'})})]})]}),"\n",(0,o.jsx)(n.h2,{id:"passing-tools-to-the-llm",children:"Passing Tools to the LLM"}),"\n",(0,o.jsxs)(n.p,{children:["For the AI to call your tools, you need to pass tool schemas when making LLM requests. The ",(0,o.jsx)(n.code,{children:"ToolRegistry"})," converts your tools to the format required by OpenAI or Anthropic."]}),"\n",(0,o.jsx)(n.h3,{id:"how-tool-calling-works",children:"How Tool Calling Works"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Tool Calling Flow                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                     \u2502\n\u2502  1. Agent prepares LLM request                                      \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502     \u2502  messages = [system_prompt, user_message]                \u2502    \u2502\n\u2502     \u2502  tools = tool_registry.get_openai_schemas()  \u25c4\u2500\u2500 Tools   \u2502    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  2. LLM decides to call tools                                       \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502     \u2502  Response: tool_calls=[                                  \u2502    \u2502\n\u2502     \u2502    {name: "get_weather", args: {city: "Paris"}}          \u2502    \u2502\n\u2502     \u2502  ]                                                       \u2502    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  3. Agent executes tools                                            \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502     \u2502  tool = registry.get("get_weather")                      \u2502    \u2502\n\u2502     \u2502  result = await tool.execute(city="Paris")               \u2502    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  4. Results sent back to LLM                                        \u2502\n\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502     \u2502  messages.append(tool_result_message)                    \u2502    \u2502\n\u2502     \u2502  response = await llm.generate(messages, tools)          \u2502    \u2502\n\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                      \u2502\n\u2502                              \u25bc                                      \u2502\n\u2502  5. LLM generates final response (or calls more tools)              \u2502\n\u2502                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n'})}),"\n",(0,o.jsx)(n.h3,{id:"getting-tool-schemas",children:"Getting Tool Schemas"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"ToolRegistry"})," provides methods to get tool schemas in different formats:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from stella_agent_sdk.tools import ToolRegistry\n\nregistry = ToolRegistry()\nregistry.register(GetWeatherTool())\nregistry.register(QueryDatabaseTool())\n\n# Get schemas for OpenAI\nopenai_tools = registry.get_openai_schemas()\n# Returns: [{"type": "function", "function": {"name": ..., "parameters": ...}}, ...]\n\n# Get schemas for Anthropic\nanthropic_tools = registry.get_anthropic_schemas()\n# Returns: [{"name": ..., "input_schema": ...}, ...]\n'})}),"\n",(0,o.jsx)(n.h3,{id:"complete-llm-integration-example",children:"Complete LLM Integration Example"}),"\n",(0,o.jsx)(n.p,{children:"Here's a complete example showing how to pass tools to an LLM and handle the response:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="agent.py"',children:'from stella_agent_sdk.tools import ToolRegistry, ToolExecutor\nfrom openai import AsyncOpenAI\n\n\nclass MyAgent:\n    def __init__(self):\n        self.client = AsyncOpenAI()\n        self.tool_registry = ToolRegistry()\n        self.tool_executor = ToolExecutor(self.tool_registry)\n\n        # Register your custom tools\n        self.tool_registry.register(GetWeatherTool())\n        self.tool_registry.register(SearchProductsTool())\n\n    async def generate_response(\n        self,\n        system_prompt: str,\n        user_message: str\n    ) -> str:\n        """Generate a response, handling any tool calls."""\n\n        messages = [\n            {"role": "system", "content": system_prompt},\n            {"role": "user", "content": user_message}\n        ]\n\n        # Get tool schemas from registry\n        tools = self.tool_registry.get_openai_schemas()\n\n        # Loop until LLM responds without tool calls\n        max_iterations = 10\n        for _ in range(max_iterations):\n            # Call LLM with tools\n            response = await self.client.chat.completions.create(\n                model="gpt-4o",\n                messages=messages,\n                tools=tools,        # Pass tools here\n                tool_choice="auto"  # Let LLM decide when to use tools\n            )\n\n            choice = response.choices[0]\n\n            # If no tool calls, return the text response\n            if not choice.message.tool_calls:\n                return choice.message.content\n\n            # Add assistant message with tool calls to history\n            messages.append(choice.message)\n\n            # Execute each tool call\n            for tool_call in choice.message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                print(f"Executing tool: {tool_name}({tool_args})")\n\n                # Look up and execute the tool\n                tool = self.tool_registry.get(tool_name)\n                if tool:\n                    result = await tool.execute(**tool_args)\n                else:\n                    result = ToolResult(\n                        success=False,\n                        error=f"Unknown tool: {tool_name}"\n                    )\n\n                # Add tool result to messages\n                messages.append({\n                    "role": "tool",\n                    "tool_call_id": tool_call.id,\n                    "content": json.dumps(result.to_dict())\n                })\n\n        return "Max tool iterations reached"\n'})}),"\n",(0,o.jsx)(n.h3,{id:"using-llmservice-recommended",children:"Using LLMService (Recommended)"}),"\n",(0,o.jsxs)(n.p,{children:["The STELLA agent SDK provides ",(0,o.jsx)(n.code,{children:"LLMService"})," which handles tool calling automatically:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="Using LLMService"',children:'from stella_light_agent.llm.service import (\n    LLMService,\n    LLMConfig,\n    LLMProvider,\n    LLMMessage\n)\n\nclass MyAgent:\n    def __init__(self):\n        self.llm_service = LLMService()\n        self.tool_registry = ToolRegistry()\n\n        # Register tools\n        self.tool_registry.register(GetWeatherTool())\n\n    async def process(self, user_input: str) -> str:\n        messages = [\n            LLMMessage(role="system", content="You are a helpful assistant."),\n            LLMMessage(role="user", content=user_input)\n        ]\n\n        # Configure LLM with tools\n        config = LLMConfig(\n            provider=LLMProvider.OPENAI_DIRECT,\n            model="gpt-4o",\n            tools=self.tool_registry.get_openai_schemas(),\n            tool_choice="auto"  # "auto", "none", or "required"\n        )\n\n        response = await self.llm_service.generate(\n            messages=messages,\n            config=config\n        )\n\n        # Check if LLM made tool calls\n        if response.tool_calls:\n            for tc in response.tool_calls:\n                print(f"LLM called: {tc.name}({tc.arguments})")\n                tool = self.tool_registry.get(tc.name)\n                result = await tool.execute(**tc.arguments)\n                # ... handle result\n\n        return response.content\n'})}),"\n",(0,o.jsx)(n.h3,{id:"tool-choice-options",children:"Tool Choice Options"}),"\n",(0,o.jsxs)(n.p,{children:["Control when the LLM uses tools with ",(0,o.jsx)(n.code,{children:"tool_choice"}),":"]}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Value"}),(0,o.jsx)(n.th,{children:"Behavior"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:'"auto"'})}),(0,o.jsx)(n.td,{children:"LLM decides whether to use tools (default)"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:'"none"'})}),(0,o.jsx)(n.td,{children:"LLM won't use any tools"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:'"required"'})}),(0,o.jsx)(n.td,{children:"LLM must use at least one tool"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:'{"type": "function", "function": {"name": "specific_tool"}}'})}),(0,o.jsx)(n.td,{children:"Force a specific tool"})]})]})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'# Force the LLM to always use tools\nconfig = LLMConfig(\n    tools=tools,\n    tool_choice="required"\n)\n\n# Prevent tool usage for this request\nconfig = LLMConfig(\n    tools=tools,\n    tool_choice="none"\n)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"parallel-tool-execution",children:"Parallel Tool Execution"}),"\n",(0,o.jsx)(n.p,{children:"When the LLM requests multiple tools, execute them in parallel for better performance:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import asyncio\n\nasync def execute_tools_parallel(\n    self,\n    tool_calls: list\n) -> list:\n    """Execute multiple tool calls in parallel."""\n\n    async def execute_single(tc):\n        tool = self.tool_registry.get(tc.name)\n        if not tool:\n            return ToolResult(success=False, error=f"Unknown: {tc.name}")\n        return await tool.execute(**tc.arguments)\n\n    results = await asyncio.gather(\n        *[execute_single(tc) for tc in tool_calls]\n    )\n\n    return [\n        {\n            "role": "tool",\n            "tool_call_id": tc.id,\n            "content": json.dumps(result.to_dict())\n        }\n        for tc, result in zip(tool_calls, results)\n    ]\n'})}),"\n",(0,o.jsx)(n.h2,{id:"tool-components",children:"Tool Components"}),"\n",(0,o.jsx)(n.h3,{id:"basetool-properties",children:"BaseTool Properties"}),"\n",(0,o.jsx)(n.p,{children:"Every tool must implement these properties:"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Property"}),(0,o.jsx)(n.th,{children:"Type"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"name"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"str"})}),(0,o.jsx)(n.td,{children:"Unique identifier (snake_case)"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"description"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"str"})}),(0,o.jsx)(n.td,{children:"Description for the LLM"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"parameters_schema"})}),(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"Dict"})}),(0,o.jsx)(n.td,{children:"JSON Schema for parameters"})]})]})]}),"\n",(0,o.jsx)(n.h3,{id:"toolresult",children:"ToolResult"}),"\n",(0,o.jsxs)(n.p,{children:["Return a ",(0,o.jsx)(n.code,{children:"ToolResult"})," from every ",(0,o.jsx)(n.code,{children:"execute()"})," call:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from stella_agent_sdk.tools import ToolResult\n\n# Success with data\nreturn ToolResult(\n    success=True,\n    data={"key": "value", "count": 42}\n)\n\n# Failure with error message\nreturn ToolResult(\n    success=False,\n    error="Database connection failed"\n)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"parameters-schema",children:"Parameters Schema"}),"\n",(0,o.jsx)(n.p,{children:"Use JSON Schema format for parameters:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'@property\ndef parameters_schema(self) -> Dict[str, Any]:\n    return {\n        "type": "object",\n        "properties": {\n            "required_param": {\n                "type": "string",\n                "description": "This parameter is required"\n            },\n            "optional_param": {\n                "type": "integer",\n                "description": "Optional with default"\n            },\n            "enum_param": {\n                "type": "string",\n                "enum": ["option1", "option2", "option3"],\n                "description": "Must be one of the options"\n            },\n            "array_param": {\n                "type": "array",\n                "items": {"type": "string"},\n                "description": "List of strings"\n            }\n        },\n        "required": ["required_param"]\n    }\n'})}),"\n",(0,o.jsx)(n.h2,{id:"example-database-tool",children:"Example: Database Tool"}),"\n",(0,o.jsx)(n.p,{children:"A tool that queries a database:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="tools/database.py"',children:'from typing import Any, Dict, List\n\nfrom stella_agent_sdk.tools import BaseTool, ToolResult\n\n\nclass QueryDatabaseTool(BaseTool):\n    """Query the application database."""\n\n    def __init__(self, db_client):\n        self._db = db_client\n\n    @property\n    def name(self) -> str:\n        return "query_database"\n\n    @property\n    def description(self) -> str:\n        return (\n            "Query the database for records. Supports filtering "\n            "by field values and limiting results."\n        )\n\n    @property\n    def parameters_schema(self) -> Dict[str, Any]:\n        return {\n            "type": "object",\n            "properties": {\n                "table": {\n                    "type": "string",\n                    "enum": ["users", "orders", "products"],\n                    "description": "Table to query"\n                },\n                "filters": {\n                    "type": "object",\n                    "description": "Field-value pairs to filter by"\n                },\n                "limit": {\n                    "type": "integer",\n                    "description": "Max records to return (default: 10)"\n                }\n            },\n            "required": ["table"]\n        }\n\n    async def execute(\n        self,\n        table: str,\n        filters: Dict[str, Any] = None,\n        limit: int = 10\n    ) -> ToolResult:\n        try:\n            query = self._db.table(table)\n\n            if filters:\n                for field, value in filters.items():\n                    query = query.where(field, "==", value)\n\n            results = await query.limit(limit).get()\n\n            return ToolResult(\n                success=True,\n                data={\n                    "table": table,\n                    "count": len(results),\n                    "records": [r.to_dict() for r in results]\n                }\n            )\n        except Exception as e:\n            return ToolResult(\n                success=False,\n                error=f"Query failed: {str(e)}"\n            )\n'})}),"\n",(0,o.jsx)(n.h2,{id:"example-external-api-tool",children:"Example: External API Tool"}),"\n",(0,o.jsx)(n.p,{children:"A tool that calls an external API with authentication:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="tools/crm.py"',children:'import os\nfrom typing import Any, Dict\n\nimport httpx\nfrom stella_agent_sdk.tools import BaseTool, ToolResult\n\n\nclass CreateCRMContactTool(BaseTool):\n    """Create a contact in the CRM system."""\n\n    def __init__(self):\n        self._api_key = os.environ.get("CRM_API_KEY")\n        self._base_url = os.environ.get("CRM_API_URL")\n\n    @property\n    def name(self) -> str:\n        return "create_crm_contact"\n\n    @property\n    def description(self) -> str:\n        return "Create a new contact in the CRM with name and email."\n\n    @property\n    def parameters_schema(self) -> Dict[str, Any]:\n        return {\n            "type": "object",\n            "properties": {\n                "name": {\n                    "type": "string",\n                    "description": "Contact\'s full name"\n                },\n                "email": {\n                    "type": "string",\n                    "description": "Contact\'s email address"\n                },\n                "phone": {\n                    "type": "string",\n                    "description": "Contact\'s phone number (optional)"\n                },\n                "notes": {\n                    "type": "string",\n                    "description": "Additional notes about the contact"\n                }\n            },\n            "required": ["name", "email"]\n        }\n\n    async def execute(\n        self,\n        name: str,\n        email: str,\n        phone: str = None,\n        notes: str = None\n    ) -> ToolResult:\n        if not self._api_key:\n            return ToolResult(\n                success=False,\n                error="CRM_API_KEY not configured"\n            )\n\n        payload = {\n            "name": name,\n            "email": email,\n        }\n        if phone:\n            payload["phone"] = phone\n        if notes:\n            payload["notes"] = notes\n\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.post(\n                    f"{self._base_url}/contacts",\n                    json=payload,\n                    headers={"Authorization": f"Bearer {self._api_key}"},\n                    timeout=30.0\n                )\n                response.raise_for_status()\n                data = response.json()\n\n            return ToolResult(\n                success=True,\n                data={\n                    "contact_id": data["id"],\n                    "message": f"Contact \'{name}\' created successfully"\n                }\n            )\n        except httpx.TimeoutException:\n            return ToolResult(\n                success=False,\n                error="CRM API request timed out"\n            )\n        except httpx.HTTPStatusError as e:\n            return ToolResult(\n                success=False,\n                error=f"CRM API error: {e.response.status_code}"\n            )\n'})}),"\n",(0,o.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,o.jsxs)(n.p,{children:["Always return ",(0,o.jsx)(n.code,{children:"ToolResult"})," - never raise exceptions:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'async def execute(self, **kwargs) -> ToolResult:\n    try:\n        result = await self._do_work(**kwargs)\n        return ToolResult(success=True, data=result)\n    except ValidationError as e:\n        return ToolResult(success=False, error=f"Invalid input: {e}")\n    except ConnectionError as e:\n        return ToolResult(success=False, error=f"Connection failed: {e}")\n    except Exception as e:\n        return ToolResult(success=False, error=f"Unexpected error: {e}")\n'})}),"\n",(0,o.jsx)(n.h3,{id:"timeouts",children:"Timeouts"}),"\n",(0,o.jsx)(n.p,{children:"Add timeouts for external calls:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import asyncio\n\nasync def execute(self, query: str) -> ToolResult:\n    try:\n        result = await asyncio.wait_for(\n            self._external_api.call(query),\n            timeout=30.0\n        )\n        return ToolResult(success=True, data=result)\n    except asyncio.TimeoutError:\n        return ToolResult(\n            success=False,\n            error="Operation timed out after 30 seconds"\n        )\n'})}),"\n",(0,o.jsx)(n.h3,{id:"descriptive-names-and-descriptions",children:"Descriptive Names and Descriptions"}),"\n",(0,o.jsx)(n.p,{children:"The LLM uses your tool's name and description to decide when to call it:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'# Good - clear and specific\n@property\ndef name(self) -> str:\n    return "search_knowledge_base"\n\n@property\ndef description(self) -> str:\n    return (\n        "Search the company knowledge base for articles matching a query. "\n        "Use this when the user asks questions about company policies, "\n        "procedures, or product documentation."\n    )\n\n# Bad - vague\n@property\ndef name(self) -> str:\n    return "search"\n\n@property\ndef description(self) -> str:\n    return "Searches for stuff"\n'})}),"\n",(0,o.jsx)(n.h3,{id:"dependency-injection",children:"Dependency Injection"}),"\n",(0,o.jsx)(n.p,{children:"Pass dependencies through the constructor:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class MyTool(BaseTool):\n    def __init__(self, db_client, api_client, config):\n        self._db = db_client\n        self._api = api_client\n        self._config = config\n\n# In agent.py\ntool = MyTool(\n    db_client=self.database,\n    api_client=self.http_client,\n    config=self.tool_config\n)\nself.tool_registry.register(tool)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"testing-tools",children:"Testing Tools"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import pytest\nfrom unittest.mock import AsyncMock, patch\n\nfrom your_agent.tools import GetWeatherTool\n\n\n@pytest.mark.asyncio\nasync def test_get_weather_success():\n    tool = GetWeatherTool()\n\n    with patch.object(tool, \'_fetch_weather\', new_callable=AsyncMock) as mock:\n        mock.return_value = {\n            "temp": 72,\n            "conditions": "sunny",\n            "humidity": 45\n        }\n\n        result = await tool.execute(city="San Francisco")\n\n        assert result.success is True\n        assert result.data["temperature"] == 72\n        assert result.data["conditions"] == "sunny"\n        mock.assert_called_once_with("San Francisco", "celsius")\n\n\n@pytest.mark.asyncio\nasync def test_get_weather_api_error():\n    tool = GetWeatherTool()\n\n    with patch.object(tool, \'_fetch_weather\', new_callable=AsyncMock) as mock:\n        mock.side_effect = Exception("API unavailable")\n\n        result = await tool.execute(city="Unknown City")\n\n        assert result.success is False\n        assert "Failed to fetch weather" in result.error\n'})}),"\n",(0,o.jsx)(n.h2,{id:"built-in-tools",children:"Built-in Tools"}),"\n",(0,o.jsx)(n.p,{children:"The SDK includes tools for state machine integration:"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Tool"}),(0,o.jsx)(n.th,{children:"Purpose"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"CompleteTaskTool"})}),(0,o.jsx)(n.td,{children:"Mark conversation tasks as completed"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"SetDeliverableTool"})}),(0,o.jsx)(n.td,{children:"Set collected values from conversation"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"GetCurrentStateTool"})}),(0,o.jsx)(n.td,{children:"Query current conversation state"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"GetPendingTasksTool"})}),(0,o.jsx)(n.td,{children:"List pending tasks"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"GetPendingDeliverablesTool"})}),(0,o.jsx)(n.td,{children:"List uncollected deliverables"})]})]})]}),"\n",(0,o.jsx)(n.p,{children:"Use the factory function to create them:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"from stella_agent_sdk.tools.state_machine import create_state_machine_tools\n\ntools = create_state_machine_tools(state_machine_client)\nfor tool in tools:\n    self.tool_registry.register(tool)\n"})}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/sdk/tools",children:"SDK Tools Reference"})," - API documentation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/sdk/base-agent",children:"Base Agent"})," - Full agent API"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.a,{href:"/docs/guides/build-your-own-agent",children:"Build Your Own Agent"})," - Complete agent tutorial"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}}}]);