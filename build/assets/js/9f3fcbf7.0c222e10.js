"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[6903],{2076(e,n,s){s.d(n,{gj:()=>l,pn:()=>r});s(6540);var t=s(7714),i=s(4848);function r({number:e,title:n,children:s,code:r,language:l="bash",isLast:a=!1}){return(0,i.jsxs)("div",{className:"step",children:[(0,i.jsxs)("div",{className:"step__indicator",children:[(0,i.jsx)("div",{className:"step__number",children:e}),!a&&(0,i.jsx)("div",{className:"step__connector"})]}),(0,i.jsxs)("div",{className:"step__body",children:[(0,i.jsx)("h3",{className:"step__title",children:n}),(0,i.jsx)("div",{className:"step__content",children:s}),r&&(0,i.jsx)("div",{className:"step__code",children:(0,i.jsx)(t.A,{language:l,children:r})})]})]})}function l({children:e}){return(0,i.jsx)("div",{className:"steps",children:e})}},5459(e,n,s){s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"guides/build-your-own-agent","title":"Build Your Own Agent","description":"Build a custom conversational AI agent with the STELLA SDK","source":"@site/docs/guides/build-your-own-agent.md","sourceDirName":"guides","slug":"/guides/build-your-own-agent","permalink":"/STELLA_backend/docs/guides/build-your-own-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/c4dhi/STELLA_backend/tree/main/docs-site/docs/guides/build-your-own-agent.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Build Your Own Agent","description":"Build a custom conversational AI agent with the STELLA SDK"},"sidebar":"docsSidebar","previous":{"title":"Getting Started","permalink":"/STELLA_backend/docs/guides/getting-started"},"next":{"title":"Custom Tools","permalink":"/STELLA_backend/docs/guides/custom-tools"}}');var i=s(4848),r=s(8453),l=s(2076);const a={sidebar_position:2,title:"Build Your Own Agent",description:"Build a custom conversational AI agent with the STELLA SDK"},o="Build Your Own Agent",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Project Setup",id:"project-setup",level:2},{value:"Adding Custom Tools",id:"adding-custom-tools",level:2},{value:"Handling Tool Calls",id:"handling-tool-calls",level:2},{value:"Accessing Chat History",id:"accessing-chat-history",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"Method Reference",id:"method-reference",level:3},{value:"ChatMessage Structure",id:"chatmessage-structure",level:3},{value:"Checking Availability",id:"checking-availability",level:3},{value:"Building and Deploying",id:"building-and-deploying",level:2},{value:"Dockerfile",id:"dockerfile",level:3},{value:"Build and Push",id:"build-and-push",level:3},{value:"Register with STELLA",id:"register-with-stella",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"build-your-own-agent",children:"Build Your Own Agent"})}),"\n",(0,i.jsx)(n.p,{children:"The Agent SDK lets you focus purely on your agent's logic. STELLA handles the infrastructure\u2014audio pipeline, WebRTC streaming, session lifecycle, and deployment orchestration\u2014so you can concentrate on what makes your agent unique."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"What STELLA handles:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Audio pipeline (STT and TTS)"}),"\n",(0,i.jsx)(n.li,{children:"WebRTC streaming via LiveKit"}),"\n",(0,i.jsx)(n.li,{children:"Session creation, state management, and cleanup"}),"\n",(0,i.jsx)(n.li,{children:"Deployment and scaling"}),"\n",(0,i.jsx)(n.li,{children:"Message recording and transcript storage"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"What you implement:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Conversation logic and prompts"}),"\n",(0,i.jsx)(n.li,{children:"Tool calls and integrations"}),"\n",(0,i.jsx)(n.li,{children:"Business rules and workflows"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"By the end of this guide, you'll have a working agent that can handle voice conversations, use custom tools, and integrate with your own services."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"STELLA agents are Python applications that:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Connect to LiveKit rooms for real-time audio"}),"\n",(0,i.jsx)(n.li,{children:"Process speech-to-text (STT) and text-to-speech (TTS)"}),"\n",(0,i.jsx)(n.li,{children:"Use LLMs to generate intelligent responses"}),"\n",(0,i.jsx)(n.li,{children:"Execute custom tools to interact with external systems"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"project-setup",children:"Project Setup"}),"\n",(0,i.jsxs)(l.gj,{children:[(0,i.jsxs)(l.pn,{number:1,title:"Create the project structure",children:[(0,i.jsx)(n.p,{children:"Set up your agent project with the following structure:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",metastring:'title=""',children:"my-agent/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent.py           # Main agent class\n\u2502   \u251c\u2500\u2500 tools.py           # Custom tools\n\u2502   \u2514\u2500\u2500 config.py          # Configuration\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 .env\n"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",metastring:'title="terminal"',children:"mkdir -p my-agent/src\ncd my-agent\ntouch src/__init__.py src/agent.py src/tools.py src/config.py\ntouch Dockerfile requirements.txt .env\n"})})]}),(0,i.jsxs)(l.pn,{number:2,title:"Define your dependencies",children:[(0,i.jsxs)(n.p,{children:["Create your ",(0,i.jsx)(n.code,{children:"requirements.txt"})," with the necessary packages:"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-txt",metastring:'title="requirements.txt"',children:"stella-agent-sdk>=1.0.0\nopenai>=1.0.0\nlivekit>=0.10.0\npydantic-settings>=2.0.0\n"})})]}),(0,i.jsxs)(l.pn,{number:3,title:"Configure the agent",children:[(0,i.jsxs)(n.p,{children:["Create your configuration in ",(0,i.jsx)(n.code,{children:"src/config.py"}),":"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="src/config.py"',children:'from pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    # LiveKit connection\n    livekit_url: str\n    livekit_api_key: str\n    livekit_api_secret: str\n\n    # OpenAI\n    openai_api_key: str\n    openai_model: str = "gpt-4o"\n\n    # Audio pipeline\n    stt_provider: str = "sherpa"\n    tts_provider: str = "kokoro"\n\n    # Session\n    room_name: str\n    participant_identity: str = "agent"\n\n    class Config:\n        env_file = ".env"\n\n\nsettings = Settings()\n'})})]}),(0,i.jsxs)(l.pn,{number:4,title:"Implement the agent",isLast:!0,children:[(0,i.jsxs)(n.p,{children:["Create your main agent class in ",(0,i.jsx)(n.code,{children:"src/agent.py"}),":"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="src/agent.py"',children:'from openai import AsyncOpenAI\nfrom stella_sdk import BaseAgent, AudioPipeline\n\nfrom .config import settings\n\n\nclass MyCustomAgent(BaseAgent):\n    """A custom conversational AI agent."""\n\n    def __init__(self):\n        super().__init__()\n        self.pipeline = AudioPipeline(\n            stt_provider=settings.stt_provider,\n            tts_provider=settings.tts_provider\n        )\n        self.openai = AsyncOpenAI()\n        self.history = []\n\n    async def on_connect(self):\n        """Called when the agent connects to the LiveKit room."""\n        print(f"Connected to room: {self.room_name}")\n\n        # Send a greeting\n        greeting = "Hello! How can I help you today?"\n        await self.speak(greeting)\n\n    async def on_transcript(self, text: str, is_final: bool):\n        """Handle transcribed user speech."""\n        if not is_final:\n            return\n\n        # Add to history\n        self.history.append({"role": "user", "content": text})\n\n        # Generate response\n        response = await self.generate_response(text)\n\n        # Speak the response\n        await self.speak(response)\n\n        # Add to history\n        self.history.append({"role": "assistant", "content": response})\n\n    async def generate_response(self, user_input: str) -> str:\n        """Generate a response using OpenAI."""\n        response = await self.openai.chat.completions.create(\n            model=settings.openai_model,\n            messages=[\n                {"role": "system", "content": "You are a helpful assistant."},\n                *self.history\n            ]\n        )\n        return response.choices[0].message.content\n\n    async def speak(self, text: str):\n        """Convert text to speech and publish to the room."""\n        async for audio_chunk in self.pipeline.text_to_speech_stream(text):\n            await self.publish_audio(audio_chunk)\n\n\ndef main():\n    agent = MyCustomAgent()\n    agent.run()\n\n\nif __name__ == "__main__":\n    main()\n'})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"adding-custom-tools",children:"Adding Custom Tools"}),"\n",(0,i.jsx)(n.p,{children:"Tools allow your agent to perform actions beyond conversation. Here's how to add a search tool:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="src/tools.py"',children:'from stella_sdk import tool\n\n\n@tool\nasync def search_database(query: str, limit: int = 5) -> dict:\n    """Search the database for relevant information.\n\n    Args:\n        query: The search query\n        limit: Maximum number of results\n\n    Returns:\n        Search results\n    """\n    # Your database search logic here\n    results = await db.search(query, limit=limit)\n\n    return {\n        "found": len(results) > 0,\n        "results": [\n            {"title": r.title, "content": r.content}\n            for r in results\n        ]\n    }\n\n\n@tool\nasync def create_task(title: str, description: str) -> dict:\n    """Create a new task in the task management system.\n\n    Args:\n        title: Task title\n        description: Task description\n\n    Returns:\n        Created task details\n    """\n    task = await task_service.create(title=title, description=description)\n\n    return {\n        "task_id": task.id,\n        "status": "created",\n        "message": f"Task \'{title}\' created successfully"\n    }\n'})}),"\n",(0,i.jsx)(n.p,{children:"Register tools in your agent:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title="src/agent.py"',children:"from .tools import search_database, create_task\n\n\nclass MyCustomAgent(BaseAgent):\n    def __init__(self):\n        super().__init__()\n        # ... other initialization\n\n        # Register tools\n        self.register_tool(search_database)\n        self.register_tool(create_task)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"handling-tool-calls",children:"Handling Tool Calls"}),"\n",(0,i.jsx)(n.p,{children:"When the LLM wants to use a tool, handle it in your response generation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",metastring:'title=""',children:'async def generate_response(self, user_input: str) -> str:\n    messages = [\n        {"role": "system", "content": self.system_prompt},\n        *self.history\n    ]\n\n    response = await self.openai.chat.completions.create(\n        model=settings.openai_model,\n        messages=messages,\n        tools=self.get_tool_definitions()\n    )\n\n    # Handle tool calls\n    while response.choices[0].message.tool_calls:\n        tool_calls = response.choices[0].message.tool_calls\n        messages.append(response.choices[0].message)\n\n        for tool_call in tool_calls:\n            # Execute the tool\n            result = await self.execute_tool(\n                tool_call.function.name,\n                json.loads(tool_call.function.arguments)\n            )\n\n            messages.append({\n                "role": "tool",\n                "tool_call_id": tool_call.id,\n                "content": json.dumps(result)\n            })\n\n        # Get next response\n        response = await self.openai.chat.completions.create(\n            model=settings.openai_model,\n            messages=messages,\n            tools=self.get_tool_definitions()\n        )\n\n    return response.choices[0].message.content\n'})}),"\n",(0,i.jsx)(n.h2,{id:"accessing-chat-history",children:"Accessing Chat History"}),"\n",(0,i.jsxs)(n.p,{children:["STELLA automatically records all messages exchanged during a session\u2014you don't need to implement any recording logic. Your agent can retrieve this conversation history using the built-in ",(0,i.jsx)(n.code,{children:"get_chat_history()"})," method."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"No setup required:"})," The platform handles message recording, storage, and retrieval. Your agent just calls the method."]}),"\n",(0,i.jsx)(n.p,{children:"This is useful for:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Building context for LLM prompts"}),"\n",(0,i.jsx)(n.li,{children:"Resuming conversations after agent restart"}),"\n",(0,i.jsx)(n.li,{children:"Analyzing conversation patterns"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class MyAgent(BaseAgent):\n    async def process(self, input: AgentInput) -> AsyncIterator[AgentOutput]:\n        # Get recent conversation history\n        history = await self.get_chat_history(limit=20)\n\n        # Build context for LLM\n        context = "\\n".join([\n            f"{msg.role}: {msg.content}"\n            for msg in history\n        ])\n\n        # Use in your prompt\n        response = await self.llm.chat([\n            {"role": "system", "content": f"Previous conversation:\\n{context}"},\n            {"role": "user", "content": input.text}\n        ])\n\n        yield AgentOutput.text_final(input.session_id, response)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"method-reference",children:"Method Reference"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"await self.get_chat_history(\n    include_debug: bool = False,  # Include debug/processing messages\n    limit: int = 100,             # Max messages (up to 500)\n) -> List[ChatMessage]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"chatmessage-structure",children:"ChatMessage Structure"}),"\n",(0,i.jsx)(n.p,{children:"Each message includes:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"id"})," - Unique message identifier"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"timestamp"})," - ISO 8601 timestamp"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"role"})," - Sender role ('user', 'assistant', 'system')"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"content"})," - Extracted text content"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"message_type"})," - Type ('user_text', 'transcript', 'agent_text')"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"envelope"})," - Full original message envelope"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"checking-availability",children:"Checking Availability"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"if self.has_history:\n    history = await self.get_chat_history()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"building-and-deploying",children:"Building and Deploying"}),"\n",(0,i.jsx)(n.h3,{id:"dockerfile",children:"Dockerfile"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-dockerfile",metastring:'title="Dockerfile"',children:'FROM python:3.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    ffmpeg \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy source code\nCOPY src/ ./src/\n\nENV PYTHONPATH=/app\n\nCMD ["python", "-m", "src.agent"]\n'})}),"\n",(0,i.jsx)(n.h3,{id:"build-and-push",children:"Build and Push"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",metastring:'title="terminal"',children:"# Build the image\ndocker build -t my-custom-agent:latest .\n\n# Test locally\ndocker run --env-file .env my-custom-agent:latest\n\n# Push to registry\ndocker tag my-custom-agent:latest registry.example.com/my-custom-agent:latest\ndocker push registry.example.com/my-custom-agent:latest\n"})}),"\n",(0,i.jsx)(n.h3,{id:"register-with-stella",children:"Register with STELLA"}),"\n",(0,i.jsx)(n.p,{children:"Add your agent to the STELLA configuration so it can be deployed:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",metastring:'title="agents-config.yaml"',children:'agents:\n  - name: my-custom-agent\n    image: registry.example.com/my-custom-agent:latest\n    resources:\n      requests:\n        cpu: "250m"\n        memory: "512Mi"\n      limits:\n        cpu: "1000m"\n        memory: "2Gi"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error Handling"}),": Always wrap external API calls in try/catch blocks"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Logging"}),": Add comprehensive logging for debugging production issues"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Timeouts"}),": Set appropriate timeouts for tool executions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Rate Limiting"}),": Respect API rate limits for external services"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Testing"}),": Write unit tests for tools and response generation"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/guides/add-custom-ui",children:"Add Custom UI"})," - Customize the frontend"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/sdk/base-agent",children:"Base Agent Reference"})," - Full API documentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"/docs/sdk/tools",children:"Tools Reference"})," - Advanced tool patterns"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);