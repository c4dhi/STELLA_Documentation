"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[5563],{8453(e,n,t){t.d(n,{R:()=>a,x:()=>o});var s=t(6540);const i={},r=s.createContext(i);function a(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:n},e.children)}},9678(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"agent-sdk/building-custom-agent","title":"\ud83d\udee0\ufe0f Building Custom Agents","description":"This comprehensive guide walks you through building a complete custom agent from scratch.","source":"@site/docs/agent-sdk/building-custom-agent.md","sourceDirName":"agent-sdk","slug":"/agent-sdk/building-custom-agent","permalink":"/STELLA_backend/docs/agent-sdk/building-custom-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/c4dhi/STELLA_backend/tree/main/docs-site/docs/agent-sdk/building-custom-agent.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"\ud83d\udee0\ufe0f Building Custom Agents"}}');var i=t(4848),r=t(8453);const a={sidebar_position:8,title:"\ud83d\udee0\ufe0f Building Custom Agents"},o="\ud83d\udee0\ufe0f Building Custom Agents",l={},c=[{value:"Project Structure",id:"project-structure",level:2},{value:"Step 1: Define Your Agent",id:"step-1-define-your-agent",level:2},{value:"Step 2: Create Tools",id:"step-2-create-tools",level:2},{value:"Step 3: Define System Prompt",id:"step-3-define-system-prompt",level:2},{value:"Step 4: Configuration",id:"step-4-configuration",level:2},{value:"Step 5: Dockerfile",id:"step-5-dockerfile",level:2},{value:"Step 6: Requirements",id:"step-6-requirements",level:2},{value:"Step 7: Testing",id:"step-7-testing",level:2},{value:"Step 8: Build and Deploy",id:"step-8-build-and-deploy",level:2},{value:"Step 9: Register with STELLA",id:"step-9-register-with-stella",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"See Also",id:"see-also",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"\ufe0f-building-custom-agents",children:"\ud83d\udee0\ufe0f Building Custom Agents"})}),"\n",(0,i.jsx)(n.p,{children:"This comprehensive guide walks you through building a complete custom agent from scratch."}),"\n",(0,i.jsx)(n.h2,{id:"project-structure",children:"Project Structure"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"my-agent/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 agent.py           # Main agent class\n\u2502   \u251c\u2500\u2500 tools/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 knowledge.py   # Custom tools\n\u2502   \u251c\u2500\u2500 prompts/\n\u2502   \u2502   \u2514\u2500\u2500 system.py      # System prompts\n\u2502   \u2514\u2500\u2500 config.py          # Configuration\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_agent.py\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 README.md\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-1-define-your-agent",children:"Step 1: Define Your Agent"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"src/agent.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom openai import AsyncOpenAI\nfrom stella_sdk import BaseAgent, AudioPipeline, TodoItem\nfrom stella_sdk.messages import TranscriptMessage, StatusMessage\n\nfrom .tools import search_knowledge, create_ticket\nfrom .prompts import SYSTEM_PROMPT\nfrom .config import settings\n\n\nclass CustomerSupportAgent(BaseAgent):\n    """A customer support agent that can search knowledge and create tickets."""\n\n    def __init__(self):\n        super().__init__()\n\n        # Initialize components\n        self.pipeline = AudioPipeline(\n            stt_provider=settings.stt_provider,\n            tts_provider=settings.tts_provider\n        )\n        self.openai = AsyncOpenAI()\n        self.history = []\n        self.current_ticket = None\n\n        # Register tools\n        self.register_tool(search_knowledge)\n        self.register_tool(create_ticket)\n\n    async def on_connect(self):\n        """Handle connection to LiveKit room."""\n        print(f"Connected to room: {self.room_name}")\n\n        # Initialize todo list\n        await self.update_todo([\n            TodoItem(id="greet", description="Greet customer", status="in_progress"),\n            TodoItem(id="understand", description="Understand issue", status="pending"),\n            TodoItem(id="research", description="Research solution", status="pending"),\n            TodoItem(id="resolve", description="Resolve or escalate", status="pending")\n        ])\n\n        # Send greeting\n        await self.send_status("speaking")\n        greeting = "Hello! I\'m your customer support assistant. How can I help you today?"\n        await self.speak(greeting)\n\n        # Update tasks\n        await self.complete_task("greet")\n        await self.send_status("listening")\n\n    async def on_disconnect(self):\n        """Handle disconnection."""\n        print(f"Session ended. Conversation had {len(self.history)} turns.")\n\n    async def on_transcript(self, text: str, is_final: bool):\n        """Handle transcribed user speech."""\n        # Send interim transcripts to frontend\n        await self.send_transcript(text, speaker="user", is_final=is_final)\n\n        if not is_final:\n            return\n\n        # Add to history\n        self.history.append({"role": "user", "content": text})\n\n        # Process the message\n        await self.start_task("understand")\n        await self.send_status("thinking", "Understanding your request...")\n\n        # Generate response (may involve tool calls)\n        response = await self.generate_response(text)\n\n        # Speak the response\n        await self.send_status("speaking")\n        await self.speak(response)\n\n        # Add to history\n        self.history.append({"role": "assistant", "content": response})\n\n        await self.send_status("listening")\n\n    async def on_data_message(self, message: dict):\n        """Handle data channel messages."""\n        if message.get("type") == "user_text":\n            # Handle text input same as voice\n            await self.on_transcript(message["data"], is_final=True)\n\n        elif message.get("type") == "control":\n            action = message["data"].get("action")\n            if action == "interrupt":\n                await self.pipeline.cancel_tts()\n                await self.send_status("listening")\n\n    async def generate_response(self, user_input: str) -> str:\n        """Generate a response using OpenAI with tool support."""\n        messages = [\n            {"role": "system", "content": SYSTEM_PROMPT},\n            *self.history\n        ]\n\n        response = await self.openai.chat.completions.create(\n            model=settings.openai_model,\n            messages=messages,\n            tools=self.get_tool_definitions(),\n            temperature=0.7\n        )\n\n        # Handle tool calls\n        while response.choices[0].message.tool_calls:\n            tool_calls = response.choices[0].message.tool_calls\n            messages.append(response.choices[0].message)\n\n            for tool_call in tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                # Update status\n                if tool_name == "search_knowledge":\n                    await self.start_task("research")\n                    await self.send_status("thinking", "Searching knowledge base...")\n                elif tool_name == "create_ticket":\n                    await self.start_task("resolve")\n                    await self.send_status("thinking", "Creating support ticket...")\n\n                # Execute tool\n                result = await self.execute_tool(tool_name, tool_args)\n\n                messages.append({\n                    "role": "tool",\n                    "tool_call_id": tool_call.id,\n                    "content": json.dumps(result)\n                })\n\n            # Get next response\n            response = await self.openai.chat.completions.create(\n                model=settings.openai_model,\n                messages=messages,\n                tools=self.get_tool_definitions()\n            )\n\n        return response.choices[0].message.content\n\n    async def speak(self, text: str):\n        """Convert text to speech and publish."""\n        await self.send_transcript(text, speaker="assistant")\n\n        async for audio_chunk in self.pipeline.text_to_speech_stream(text):\n            await self.publish_audio(audio_chunk)\n\n    # Helper methods for task management\n    async def start_task(self, task_id: str):\n        """Mark a task as in progress."""\n        # Implementation similar to progress tracking example\n        pass\n\n    async def complete_task(self, task_id: str):\n        """Mark a task as completed."""\n        pass\n\n\ndef main():\n    agent = CustomerSupportAgent()\n    agent.run()\n\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-2-create-tools",children:"Step 2: Create Tools"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"src/tools/knowledge.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from stella_sdk import tool\n\n\n@tool\nasync def search_knowledge(query: str, category: str = None) -> dict:\n    """Search the knowledge base for information.\n\n    Args:\n        query: The search query\n        category: Optional category filter\n\n    Returns:\n        Search results with relevant articles\n    """\n    # Your knowledge base integration\n    results = await knowledge_base.search(\n        query=query,\n        category=category,\n        limit=5\n    )\n\n    if not results:\n        return {\n            "found": False,\n            "message": "No relevant articles found"\n        }\n\n    return {\n        "found": True,\n        "articles": [\n            {\n                "title": r.title,\n                "summary": r.summary,\n                "url": r.url\n            }\n            for r in results\n        ]\n    }\n\n\n@tool\nasync def create_ticket(\n    title: str,\n    description: str,\n    priority: str = "medium",\n    customer_email: str = None\n) -> dict:\n    """Create a support ticket for the customer.\n\n    Args:\n        title: Brief title of the issue\n        description: Detailed description\n        priority: low, medium, or high\n        customer_email: Customer\'s email for follow-up\n\n    Returns:\n        Created ticket details\n    """\n    ticket = await ticket_system.create(\n        title=title,\n        description=description,\n        priority=priority,\n        customer_email=customer_email\n    )\n\n    return {\n        "ticket_id": ticket.id,\n        "status": "created",\n        "message": f"Ticket #{ticket.id} created. A support specialist will follow up within 24 hours."\n    }\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-3-define-system-prompt",children:"Step 3: Define System Prompt"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"src/prompts/system.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'SYSTEM_PROMPT = """You are a helpful customer support assistant for ACME Corp.\n\nYour role is to:\n1. Understand the customer\'s issue\n2. Search the knowledge base for relevant solutions\n3. Provide clear, helpful answers\n4. Create support tickets when issues can\'t be resolved immediately\n\nGuidelines:\n- Be friendly and professional\n- Ask clarifying questions when needed\n- Provide step-by-step instructions when applicable\n- If you can\'t solve an issue, create a ticket and assure follow-up\n- Never reveal internal system details or credentials\n\nAvailable tools:\n- search_knowledge: Search for solutions in the knowledge base\n- create_ticket: Escalate issues that require human support\n\nAlways prioritize customer satisfaction while being efficient."""\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-4-configuration",children:"Step 4: Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"src/config.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    # LiveKit\n    livekit_url: str\n    livekit_api_key: str\n    livekit_api_secret: str\n\n    # OpenAI\n    openai_api_key: str\n    openai_model: str = "gpt-4o"\n\n    # Audio\n    stt_provider: str = "sherpa"\n    tts_provider: str = "kokoro"\n    tts_voice: str = "af_heart"\n\n    # Agent\n    room_name: str\n    participant_identity: str\n\n    class Config:\n        env_file = ".env"\n\n\nsettings = Settings()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-5-dockerfile",children:"Step 5: Dockerfile"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-dockerfile",children:'FROM python:3.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    ffmpeg \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy source code\nCOPY src/ ./src/\n\n# Set environment\nENV PYTHONPATH=/app\n\n# Run agent\nCMD ["python", "-m", "src.agent"]\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-6-requirements",children:"Step 6: Requirements"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"requirements.txt"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"stella-agent-sdk>=1.0.0\nopenai>=1.0.0\nlivekit>=0.10.0\npydantic-settings>=2.0.0\naiohttp>=3.9.0\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-7-testing",children:"Step 7: Testing"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"tests/test_agent.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pytest\nfrom unittest.mock import AsyncMock, patch\nfrom src.agent import CustomerSupportAgent\n\n\n@pytest.fixture\ndef agent():\n    with patch.object(CustomerSupportAgent, \'__init__\', lambda x: None):\n        agent = CustomerSupportAgent()\n        agent.pipeline = AsyncMock()\n        agent.openai = AsyncMock()\n        agent.history = []\n        return agent\n\n\n@pytest.mark.asyncio\nasync def test_greeting_on_connect(agent):\n    agent.send_status = AsyncMock()\n    agent.speak = AsyncMock()\n    agent.update_todo = AsyncMock()\n    agent.complete_task = AsyncMock()\n    agent.room_name = "test-room"\n\n    await agent.on_connect()\n\n    agent.speak.assert_called_once()\n    assert "Hello" in agent.speak.call_args[0][0]\n\n\n@pytest.mark.asyncio\nasync def test_handles_user_message(agent):\n    agent.send_transcript = AsyncMock()\n    agent.send_status = AsyncMock()\n    agent.speak = AsyncMock()\n    agent.generate_response = AsyncMock(return_value="Test response")\n\n    await agent.on_transcript("Hello", is_final=True)\n\n    agent.generate_response.assert_called_once_with("Hello")\n    agent.speak.assert_called_once_with("Test response")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-8-build-and-deploy",children:"Step 8: Build and Deploy"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Build the image\ndocker build -t my-customer-support-agent:latest .\n\n# Test locally\ndocker run --env-file .env my-customer-support-agent:latest\n\n# Push to registry\ndocker tag my-customer-support-agent:latest registry.example.com/my-customer-support-agent:latest\ndocker push registry.example.com/my-customer-support-agent:latest\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-9-register-with-stella",children:"Step 9: Register with STELLA"}),"\n",(0,i.jsx)(n.p,{children:"Update your STELLA configuration to use the new agent:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# In your agent configuration\nagents:\n  - name: customer-support-agent\n    image: registry.example.com/my-customer-support-agent:latest\n    resources:\n      requests:\n        cpu: "250m"\n        memory: "512Mi"\n      limits:\n        cpu: "1000m"\n        memory: "2Gi"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error Handling"}),": Always handle errors gracefully and inform the user"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Logging"}),": Add comprehensive logging for debugging"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Testing"}),": Write unit tests for tools and response generation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitoring"}),": Add metrics for latency, errors, and usage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Security"}),": Validate all inputs and sanitize outputs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Rate Limiting"}),": Respect API rate limits for external services"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/agent-sdk/base-agent",children:"Base Agent"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/agent-sdk/audio-pipeline",children:"Audio Pipeline"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/agent-sdk/tools",children:"Tools"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/docs/agent-sdk/progress-tracking",children:"Progress Tracking"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);