"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[4401],{8453(n,e,t){t.d(e,{R:()=>a,x:()=>r});var o=t(6540);const i={},s=o.createContext(i);function a(n){const e=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),o.createElement(s.Provider,{value:e},n.children)}},8897(n,e,t){t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"integration/livekit","title":"LiveKit","description":"Guide for integrating LiveKit client in your frontend to connect to STELLA sessions.","source":"@site/docs/integration/livekit.md","sourceDirName":"integration","slug":"/integration/livekit","permalink":"/STELLA_backend/docs/integration/livekit","draft":false,"unlisted":false,"editUrl":"https://github.com/c4dhi/STELLA_backend/tree/main/docs-site/docs/integration/livekit.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"LiveKit"},"sidebar":"docsSidebar","previous":{"title":"Monitoring","permalink":"/STELLA_backend/docs/deployment/monitoring"},"next":{"title":"LiveKit Production","permalink":"/STELLA_backend/docs/integration/livekit-production"}}');var i=t(4848),s=t(8453);const a={sidebar_position:1,title:"LiveKit"},r="LiveKit Integration",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Installation",id:"installation",level:2},{value:"Basic Connection",id:"basic-connection",level:2},{value:"1. Get Join Token from Backend",id:"1-get-join-token-from-backend",level:3},{value:"2. Connect to LiveKit Room",id:"2-connect-to-livekit-room",level:3},{value:"Audio Integration",id:"audio-integration",level:2},{value:"Enable Microphone",id:"enable-microphone",level:3},{value:"Receive Audio from Agent",id:"receive-audio-from-agent",level:3},{value:"Audio Volume Meter",id:"audio-volume-meter",level:3},{value:"Data Channel Communication",id:"data-channel-communication",level:2},{value:"Send Text Messages",id:"send-text-messages",level:3},{value:"Receive Data Messages",id:"receive-data-messages",level:3},{value:"Message Types",id:"message-types",level:2},{value:"Transcript Chunk",id:"transcript-chunk",level:3},{value:"Agent Status",id:"agent-status",level:3},{value:"Todo List",id:"todo-list",level:3},{value:"React Integration",id:"react-integration",level:2},{value:"Custom Hook",id:"custom-hook",level:3},{value:"Component Example",id:"component-example",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Connection Issues",id:"connection-issues",level:3},{value:"Microphone Permission Denied",id:"microphone-permission-denied",level:3},{value:"Audio Not Playing",id:"audio-not-playing",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"See Also",id:"see-also",level:2}];function l(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"livekit-integration",children:"LiveKit Integration"})}),"\n",(0,i.jsx)(e.p,{children:"Guide for integrating LiveKit client in your frontend to connect to STELLA sessions."}),"\n",(0,i.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(e.p,{children:"STELLA uses LiveKit for real-time WebRTC communication. The frontend connects to LiveKit rooms to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Send/receive audio from agents"}),"\n",(0,i.jsx)(e.li,{children:"Exchange data messages (transcripts, status updates)"}),"\n",(0,i.jsx)(e.li,{children:"Track participant presence"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"npm install livekit-client\n# or\nyarn add livekit-client\n"})}),"\n",(0,i.jsx)(e.h2,{id:"basic-connection",children:"Basic Connection"}),"\n",(0,i.jsx)(e.h3,{id:"1-get-join-token-from-backend",children:"1. Get Join Token from Backend"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"async function getJoinToken(sessionId: string, userId: string, userName: string) {\n  const response = await fetch(`/api/sessions/${sessionId}/joinToken`, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      identity: userId,\n      name: userName,\n    }),\n  });\n\n  return response.json(); // { token, serverUrl, roomName }\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"2-connect-to-livekit-room",children:"2. Connect to LiveKit Room"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"import { Room } from 'livekit-client';\n\nasync function connectToSession(sessionId: string, userId: string, userName: string) {\n  // Get token from backend\n  const { token, serverUrl } = await getJoinToken(sessionId, userId, userName);\n\n  // Create room instance\n  const room = new Room({\n    adaptiveStream: true,\n    dynacast: true,\n  });\n\n  // Set up event listeners BEFORE connecting\n  room.on('connected', () => {\n    console.log('Connected to room!');\n  });\n\n  room.on('disconnected', () => {\n    console.log('Disconnected from room');\n  });\n\n  // Connect to room\n  await room.connect(serverUrl, token);\n\n  return room;\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"audio-integration",children:"Audio Integration"}),"\n",(0,i.jsx)(e.h3,{id:"enable-microphone",children:"Enable Microphone"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"import { Room, RoomEvent, Track } from 'livekit-client';\n\nasync function enableMicrophone(room: Room) {\n  try {\n    await room.localParticipant.setMicrophoneEnabled(true);\n    console.log('Microphone enabled');\n  } catch (error) {\n    console.error('Failed to enable microphone:', error);\n    throw error;\n  }\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"receive-audio-from-agent",children:"Receive Audio from Agent"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"room.on(RoomEvent.TrackSubscribed, (track, publication, participant) => {\n  if (track.kind === Track.Kind.Audio) {\n    // Agent's audio track\n    const audioElement = track.attach();\n    document.body.appendChild(audioElement);\n\n    console.log(`Subscribed to ${participant.identity}'s audio`);\n  }\n});\n"})}),"\n",(0,i.jsx)(e.h3,{id:"audio-volume-meter",children:"Audio Volume Meter"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"function setupVolumeMonitoring(room: Room) {\n  const audioContext = new AudioContext();\n\n  room.on(RoomEvent.LocalTrackPublished, (publication) => {\n    if (publication.kind === Track.Kind.Audio && publication.track) {\n      const mediaStream = new MediaStream([publication.track.mediaStreamTrack]);\n      const source = audioContext.createMediaStreamSource(mediaStream);\n      const analyser = audioContext.createAnalyser();\n\n      source.connect(analyser);\n      analyser.fftSize = 256;\n\n      const dataArray = new Uint8Array(analyser.frequencyBinCount);\n\n      function updateVolume() {\n        analyser.getByteFrequencyData(dataArray);\n        const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n        const volume = average / 255; // 0-1\n\n        // Update UI with volume\n        updateVolumeUI(volume);\n        requestAnimationFrame(updateVolume);\n      }\n\n      updateVolume();\n    }\n  });\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"data-channel-communication",children:"Data Channel Communication"}),"\n",(0,i.jsx)(e.h3,{id:"send-text-messages",children:"Send Text Messages"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"async function sendTextMessage(room: Room, message: string) {\n  const data = {\n    type: 'user_text',\n    data: message,\n  };\n\n  const encoder = new TextEncoder();\n  const encodedData = encoder.encode(JSON.stringify(data));\n\n  await room.localParticipant.publishData(encodedData, {\n    reliable: true, // Guaranteed delivery\n  });\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"receive-data-messages",children:"Receive Data Messages"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"room.on(RoomEvent.DataReceived, (payload: Uint8Array, participant) => {\n  const decoder = new TextDecoder();\n  const jsonString = decoder.decode(payload);\n\n  try {\n    const message = JSON.parse(jsonString);\n\n    switch (message.type) {\n      case 'transcript_chunk':\n        handleTranscript(message.data);\n        break;\n      case 'agent_status':\n        handleAgentStatus(message.data);\n        break;\n      case 'todo_list':\n        handleTodoList(message.data);\n        break;\n    }\n  } catch (error) {\n    console.error('Failed to parse data message:', error);\n  }\n});\n"})}),"\n",(0,i.jsx)(e.h2,{id:"message-types",children:"Message Types"}),"\n",(0,i.jsx)(e.h3,{id:"transcript-chunk",children:"Transcript Chunk"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"interface TranscriptChunk {\n  type: 'transcript_chunk';\n  data: {\n    text: string;\n    is_final: boolean;\n    confidence: number;\n    timestamp: string;\n    participant_id: string;\n    chunk_id: string;\n    transcript_id: string;\n  };\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"agent-status",children:"Agent Status"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"interface AgentStatus {\n  type: 'agent_status';\n  data: {\n    status: 'listening' | 'thinking' | 'speaking';\n    message?: string;\n  };\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"todo-list",children:"Todo List"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"interface TodoList {\n  type: 'todo_list';\n  data: {\n    items: Array<{\n      id: string;\n      description: string;\n      status: 'pending' | 'in_progress' | 'completed';\n      required: boolean;\n    }>;\n    timestamp: string;\n  };\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"react-integration",children:"React Integration"}),"\n",(0,i.jsx)(e.h3,{id:"custom-hook",children:"Custom Hook"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"import { useState, useEffect, useCallback } from 'react';\nimport { Room, RoomEvent, Track } from 'livekit-client';\n\ninterface UseSessionOptions {\n  sessionId: string;\n  userId: string;\n  userName: string;\n  onTranscript?: (data: any) => void;\n  onTodoList?: (data: any) => void;\n  onAgentStatus?: (data: any) => void;\n}\n\nexport function useSession(options: UseSessionOptions) {\n  const [room, setRoom] = useState<Room | null>(null);\n  const [connected, setConnected] = useState(false);\n  const [participants, setParticipants] = useState<string[]>([]);\n  const [micEnabled, setMicEnabled] = useState(false);\n\n  useEffect(() => {\n    let currentRoom: Room | null = null;\n\n    async function connect() {\n      const response = await fetch(\n        `/api/sessions/${options.sessionId}/joinToken`,\n        {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({\n            identity: options.userId,\n            name: options.userName,\n          }),\n        }\n      );\n      const { token, serverUrl } = await response.json();\n\n      currentRoom = new Room();\n\n      currentRoom.on(RoomEvent.Connected, () => setConnected(true));\n      currentRoom.on(RoomEvent.Disconnected, () => setConnected(false));\n\n      currentRoom.on(RoomEvent.ParticipantConnected, (participant) => {\n        setParticipants((prev) => [...prev, participant.identity]);\n      });\n\n      currentRoom.on(RoomEvent.ParticipantDisconnected, (participant) => {\n        setParticipants((prev) =>\n          prev.filter((id) => id !== participant.identity)\n        );\n      });\n\n      currentRoom.on(RoomEvent.DataReceived, (payload) => {\n        const decoder = new TextDecoder();\n        const message = JSON.parse(decoder.decode(payload));\n\n        if (message.type === 'transcript_chunk') {\n          options.onTranscript?.(message.data);\n        } else if (message.type === 'todo_list') {\n          options.onTodoList?.(message.data);\n        } else if (message.type === 'agent_status') {\n          options.onAgentStatus?.(message.data);\n        }\n      });\n\n      await currentRoom.connect(serverUrl, token);\n      await currentRoom.localParticipant.setMicrophoneEnabled(true);\n      setMicEnabled(true);\n      setRoom(currentRoom);\n    }\n\n    connect();\n\n    return () => {\n      currentRoom?.disconnect();\n    };\n  }, [options.sessionId, options.userId, options.userName]);\n\n  const sendMessage = useCallback(\n    async (text: string) => {\n      if (!room) return;\n\n      const data = { type: 'user_text', data: text };\n      const encoder = new TextEncoder();\n      await room.localParticipant.publishData(\n        encoder.encode(JSON.stringify(data)),\n        { reliable: true }\n      );\n    },\n    [room]\n  );\n\n  const toggleMicrophone = useCallback(async () => {\n    if (!room) return;\n\n    const newState = !micEnabled;\n    await room.localParticipant.setMicrophoneEnabled(newState);\n    setMicEnabled(newState);\n  }, [room, micEnabled]);\n\n  return {\n    connected,\n    participants,\n    micEnabled,\n    sendMessage,\n    toggleMicrophone,\n  };\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"component-example",children:"Component Example"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"function SessionView({ sessionId }: { sessionId: string }) {\n  const [messages, setMessages] = useState<string[]>([]);\n  const [input, setInput] = useState('');\n\n  const { connected, micEnabled, sendMessage, toggleMicrophone } = useSession({\n    sessionId,\n    userId: 'user-123',\n    userName: 'John Doe',\n    onTranscript: (data) => {\n      if (data.is_final) {\n        setMessages((prev) => [...prev, data.text]);\n      }\n    },\n  });\n\n  const handleSend = () => {\n    if (input.trim()) {\n      sendMessage(input);\n      setInput('');\n    }\n  };\n\n  return (\n    <div>\n      <div>Status: {connected ? 'Connected' : 'Disconnected'}</div>\n\n      <button onClick={toggleMicrophone}>\n        {micEnabled ? 'Mute' : 'Unmute'}\n      </button>\n\n      <div>\n        {messages.map((msg, i) => (\n          <div key={i}>{msg}</div>\n        ))}\n      </div>\n\n      <input\n        value={input}\n        onChange={(e) => setInput(e.target.value)}\n        onKeyPress={(e) => e.key === 'Enter' && handleSend()}\n      />\n      <button onClick={handleSend}>Send</button>\n    </div>\n  );\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(e.h3,{id:"connection-issues",children:"Connection Issues"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"room.on(RoomEvent.ConnectionStateChanged, (state) => {\n  console.log('Connection state:', state);\n});\n\nroom.on(RoomEvent.Reconnecting, () => {\n  console.log('Reconnecting...');\n});\n\nroom.on(RoomEvent.Reconnected, () => {\n  console.log('Reconnected!');\n});\n"})}),"\n",(0,i.jsx)(e.h3,{id:"microphone-permission-denied",children:"Microphone Permission Denied"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"async function requestMicrophonePermission() {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n    stream.getTracks().forEach(track => track.stop());\n    return true;\n  } catch (error) {\n    if (error.name === 'NotAllowedError') {\n      alert('Microphone permission denied');\n    }\n    return false;\n  }\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"audio-not-playing",children:"Audio Not Playing"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"room.on(RoomEvent.TrackSubscribed, (track) => {\n  if (track.kind === Track.Kind.Audio) {\n    const element = track.attach();\n\n    // Handle autoplay restrictions\n    element.play().catch((error) => {\n      console.log('Autoplay prevented:', error);\n      // Show \"Click to enable audio\" button\n    });\n\n    document.body.appendChild(element);\n  }\n});\n"})}),"\n",(0,i.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Always disconnect on unmount"})," to free resources"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Request microphone permission early"})," for better UX"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Use reliable: true for important messages"})," (transcripts, commands)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Handle reconnection gracefully"})," with loading states"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Provide visual feedback"})," for connection status"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Implement error boundaries"})," for LiveKit errors"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"see-also",children:"See Also"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"/docs/integration/livekit-production",children:"LiveKit Production"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"/docs/agent-sdk/message-types",children:"Message Types"})}),"\n",(0,i.jsx)(e.li,{children:(0,i.jsx)(e.a,{href:"/docs/getting-started/first-agent",children:"First Agent"})}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(l,{...n})}):l(n)}}}]);